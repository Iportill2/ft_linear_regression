"""
Linear Regression Implementation

Este m√≥dulo contiene la implementaci√≥n principal del algoritmo
de regresi√≥n lineal desde cero.
"""

class LinearRegression:
    """
    Implementaci√≥n de Regresi√≥n Lineal Simple usando M√≠nimos Cuadrados.
    
    Attributes:
        slope (float): Pendiente de la l√≠nea (m)
        intercept (float): Intersecci√≥n con el eje Y (b)
        is_fitted (bool): Indica si el modelo ha sido entrenado
    """
    
    def __init__(self):
        """Inicializar el modelo de regresi√≥n lineal."""
        self.slope = None
        self.intercept = None
        self.is_fitted = False
    
    def fit(self, X, y):
        """
        Entrenar el modelo con los datos de entrada.
        
        Args:
            X (list or array): Variables independientes
            y (list or array): Variables dependientes
        """
        # Validar entrada
        if len(X) != len(y):
            raise ValueError("X e y deben tener la misma longitud")
        
        if len(X) < 2:
            raise ValueError("Se necesitan al menos 2 puntos de datos para entrenar")
        
        print("üîß Entrenando modelo con algoritmo de m√≠nimos cuadrados...")
        
        # Convertir a listas si no lo son
        X = list(X)
        y = list(y)
        
        # Calcular estad√≠sticas necesarias
        n = len(X)
        sum_x = sum(X)
        sum_y = sum(y)
        sum_xy = 0
        i = 0
        while i < len(X):
            sum_xy += X[i] * y[i]
            i += 1
        sum_x_squared = 0
        j = 0
        while j < len(X):
            sum_x_squared += X[j] * X[j]
            j += 1
        
        # Mostrar estad√≠sticas de c√°lculo
        print(f"   N√∫mero de muestras: {n}")
        print(f"   üßÆ Calculando par√°metros usando m√≠nimos cuadrados...")
        
        # Calcular denominador para la pendiente
        denominator = n * sum_x_squared - sum_x * sum_x
        
        # Verificar que no hay divisi√≥n por cero (todos los X son iguales)
        if denominator == 0:
            raise ValueError("Todos los valores X son iguales. No se puede ajustar una l√≠nea.")
        
        # Calcular pendiente (slope) usando la f√≥rmula de m√≠nimos cuadrados
        # m = (n*Œ£(xy) - Œ£(x)*Œ£(y)) / (n*Œ£(x¬≤) - (Œ£(x))¬≤)
        self.slope = (n * sum_xy - sum_x * sum_y) / denominator
        
        # Calcular intersecci√≥n (intercept) 
        # b = (Œ£(y) - m*Œ£(x)) / n
        self.intercept = (sum_y - self.slope * sum_x) / n
        
        # Marcar como entrenado
        self.is_fitted = True
        
        # Mostrar resultados
        print(f"   üìà Pendiente (m): {self.slope:.4f}")
        print(f"   üìç Intersecci√≥n (b): {self.intercept:.4f}")
        print(f"   üìù Ecuaci√≥n: y = {self.slope:.4f}x + {self.intercept:.4f}")
        print("‚úÖ Modelo entrenado exitosamente!")
        
    def predict(self, X):
        """
        Realizar predicciones con el modelo entrenado.
        
        Args:
            X (list or array): Valores para predecir
            
        Returns:
            list: Predicciones del modelo
        """
        if self.is_fitted == False:
            raise ValueError("El modelo debe ser entrenado primero")
        
        # Validar entrada
        if len(X) == 0:
            print("‚ö†Ô∏è  No hay valores para predecir")
            return []
        
        # Convertir a lista si no lo es
        X = list(X)
        
        print(f"üìà Realizando predicciones para {len(X)} valores...")
        print(f"   üìù Usando ecuaci√≥n: y = {self.slope:.4f}x + {self.intercept:.4f}")
        
        # Aplicar la ecuaci√≥n lineal: y = mx + b
        predictions = []
        for x_val in X:
            y_pred = self.slope * x_val + self.intercept
            predictions.append(y_pred)
        
        # Mostrar estad√≠sticas de las predicciones
        print(f"   üìä Predicciones generadas:")
        print(f"   üîç Rango de entrada X: [{min(X):.2f}, {max(X):.2f}]")
        print(f"   üìà Rango de predicciones: [{min(predictions):.2f}, {max(predictions):.2f}]")
        
        # Mostrar algunos ejemplos si hay pocos valores
        if len(X) <= 5:
            print("   üí° Ejemplos de predicciones:")
            for i, (x_val, y_pred) in enumerate(zip(X, predictions)):
                print(f"      x = {x_val:.2f} ‚Üí y = {y_pred:.2f}")
        
        print(f"‚úÖ {len(predictions)} predicciones completadas!")
        
        return predictions
    
    def mse(self, X, y):
        """
        Calcular el Error Cuadr√°tico Medio (Mean Squared Error).
        
        Args:
            X (list or array): Variables independientes
            y (list or array): Variables dependientes reales
            
        Returns:
            float: Valor MSE del modelo
        """
        if  self.is_fitted == False:
            raise ValueError("El modelo debe ser entrenado primero")
        
        # Validar entrada
        if len(X) != len(y):
            raise ValueError("X e y deben tener la misma longitud")
        
        if len(X) == 0:
            print("‚ö†Ô∏è  No hay datos para evaluar")
            return float('inf')
        
        print(f"üìä Calculando MSE para {len(X)} puntos...")
        
        # Hacer predicciones (sin mostrar info detallada)
        X = list(X)
        y = list(y)
        
        # Calcular predicciones sin prints
        y_pred = []
        i = 0
        while i < len(X):
            pred = self.slope * X[i] + self.intercept
            y_pred.append(pred)
            i += 1
        
        # Calcular errores cuadrados
        errores_cuadrados = []
        j = 0
        while j < len(y):
            error = y[j] - y_pred[j]
            error_cuadrado = error ** 2
            errores_cuadrados.append(error_cuadrado)
            j += 1
        
        # Calcular MSE
        mse_value = sum(errores_cuadrados) / len(errores_cuadrados)
        
        # Mostrar estad√≠sticas
        # Calcular errores individuales para estad√≠sticas
        errores = []
        k = 0
        while k < len(y):
            error = y[k] - y_pred[k]
            errores.append(error)
            k += 1
        
        print(f"   üìà MSE: {mse_value:.4f}")
        print(f"   üìä Error promedio: ¬±{(mse_value ** 0.5):.4f}")
        print(f"   üîç Rango de errores: [{min(errores):.4f}, {max(errores):.4f}]")
        
        # Interpretaci√≥n
        if mse_value < 0.1:
            print("   ‚úÖ ¬°Excelente precisi√≥n!")
        elif mse_value < 1.0:
            print("   üëç Buena precisi√≥n")
        elif mse_value < 10.0:
            print("   ‚ö†Ô∏è  Precisi√≥n moderada")
        else:
            print("   ‚ùå Baja precisi√≥n - modelo necesita mejoras")
        
        return mse_value
    
    def score(self, X, y):
        """
        Calcular el coeficiente de determinaci√≥n R¬≤.
        
        Args:
            X (list or array): Variables independientes
            y (list or array): Variables dependientes reales
            
        Returns:
            float: Valor R¬≤ del modelo (entre 0 y 1, donde 1 es perfecto)
        """
        if not self.is_fitted:
            raise ValueError("El modelo debe ser entrenado primero")
        
        # Validar entrada
        if len(X) != len(y):
            raise ValueError("X e y deben tener la misma longitud")
        
        if len(X) == 0:
            print("‚ö†Ô∏è  No hay datos para evaluar")
            return 0.0
        
        print(f"üìä Calculando R¬≤ para {len(X)} puntos...")
        
        # Convertir a listas
        X = list(X)
        y = list(y)
        
        # Calcular predicciones sin prints
        y_pred = []
        i = 0
        while i < len(X):
            pred = self.slope * X[i] + self.intercept
            y_pred.append(pred)
            i += 1
        
        # Calcular media de y reales
        y_mean = sum(y) / len(y)
        
        # Calcular suma de cuadrados total (TSS)
        ss_tot = sum((real - y_mean) ** 2 for real in y)
        
        # Calcular suma de cuadrados residual (RSS)
        ss_res = 0
        j = 0
        while j < len(y):
            ss_res += (y[j] - y_pred[j]) ** 2
            j += 1
        
        # Calcular R¬≤
        if ss_tot == 0:
            r2 = 1.0  # Caso especial: todos los y son iguales
        else:
            r2 = 1 - (ss_res / ss_tot)
        
        # Mostrar estad√≠sticas
        print(f"   üìà R¬≤: {r2:.4f}")
        print(f"   üìä Porcentaje explicado: {r2 * 100:.2f}%")
        
        # Interpretaci√≥n
        if r2 >= 0.9:
            print("   ‚úÖ ¬°Excelente ajuste!")
        elif r2 >= 0.7:
            print("   üëç Buen ajuste")
        elif r2 >= 0.5:
            print("   ‚ö†Ô∏è  Ajuste moderado")
        elif r2 >= 0.0:
            print("   ‚ùå Ajuste pobre")
        else:
            print("   üí• Modelo peor que una l√≠nea horizontal")
        
        return r2
